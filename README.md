# ML_Assignment2
Mobile Price Classification using Machine Learning

â¸»

a) Problem Statement

The objective of this project is to build and compare multiple machine learning classification models to predict the price category of a mobile phone based on its technical specifications.

Given various features such as battery power, RAM, screen resolution, internal memory, etc., the model must classify the mobile phone into one of four price categories:
	â€¢	0 â†’ Low Cost
	â€¢	1 â†’ Medium Cost
	â€¢	2 â†’ High Cost
	â€¢	3 â†’ Very High Cost

The project demonstrates end-to-end machine learning workflow including model building, evaluation, comparison, and deployment using Streamlit.

â¸»

b) Dataset Description  (1 Mark)

The dataset used is the Mobile Price Classification Dataset obtained from Kaggle.
	â€¢	Total Instances: 2000
	â€¢	Total Features: 20 numerical features
	â€¢	Target Variable: price_range (4 classes)

Features Include:
	â€¢	battery_power
	â€¢	blue
	â€¢	clock_speed
	â€¢	dual_sim
	â€¢	fc (front camera)
	â€¢	four_g
	â€¢	int_memory
	â€¢	m_dep
	â€¢	mobile_wt
	â€¢	n_cores
	â€¢	pc (primary camera)
	â€¢	px_height
	â€¢	px_width
	â€¢	ram
	â€¢	sc_h
	â€¢	sc_w
	â€¢	talk_time
	â€¢	three_g
	â€¢	touch_screen
	â€¢	wifi

All features are numerical, making preprocessing simpler.

The dataset satisfies assignment requirements:
	â€¢	Minimum 500 instances âœ”
	â€¢	Minimum 12 features âœ”

â¸»

c) Models Used and Evaluation Metrics  (6 Marks)

The following six classification models were implemented on the same dataset:
	1.	Logistic Regression
	2.	Decision Tree Classifier
	3.	K-Nearest Neighbors (KNN)
	4.	Naive Bayes (Gaussian)
	5.	Random Forest (Ensemble Model)
	6.	XGBoost (Ensemble Model)

Evaluation Metrics Used:

For each model, the following performance metrics were calculated:
	â€¢	Accuracy
	â€¢	AUC Score (One-vs-Rest for Multiclass)
	â€¢	Precision (Weighted)
	â€¢	Recall (Weighted)
	â€¢	F1 Score (Weighted)
	â€¢	Matthews Correlation Coefficient (MCC)


ðŸ“Š Comparison Table of All Models

ML Model Name	Accuracy	AUC	Precision	Recall	F1 Score	MCC
Logistic Regression	0.9750	0.999591	0.975946	0.9750	0.975020	0.966875
Decision Tree	0.8375	0.889755	0.843090	0.8375	0.837224	0.784773
KNN	0.5300	0.762890	0.569762	0.5300	0.540707	0.378880
Naive Bayes	0.7975	0.955970	0.806132	0.7975	0.799422	0.731329
Random Forest	0.9025	0.984430	0.904446	0.9025	0.902951	0.870147
XGBoost	0.9050	0.991322	0.906155	0.9050	0.905007	0.873522

Observations

ML Model Name	Observation about Model Performance
Logistic Regression	Achieved the highest accuracy (97.5%) and MCC (0.9668), indicating excellent class separation and strong linear decision boundaries in the dataset.
Decision Tree	Moderate performance with 83.75% accuracy; slightly lower AUC suggests limited generalization compared to ensemble methods.
KNN	Performed poorly (53% accuracy), possibly due to sensitivity to high-dimensional feature space and choice of k value.
Naive Bayes	Achieved reasonable AUC (0.9559) but lower accuracy due to strong independence assumption among features.
Random Forest	Strong performance (90.25% accuracy) due to ensemble averaging reducing overfitting compared to Decision Tree.
XGBoost	High AUC (0.9913) and strong overall performance; slightly below Logistic Regression in accuracy but very stable.

Deployment Details

The models were deployed using Streamlit Community Cloud.

The web application includes:
	â€¢	CSV dataset upload option
	â€¢	Model selection dropdown
	â€¢	Display of evaluation metrics
	â€¢	Confusion matrix output
